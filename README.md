# 🧪 DCGAN on CelebA (WIP)

> Work in progress — training a **Deep Convolutional GAN (DCGAN)** to generate 64×64 human face images using **TensorFlow/Keras**.  
> Built by **Mohammad Hemmat** — Computer Engineering student | AI, Robotics & Cybersecurity Enthusiast.

---

## ✨ Project Goals
- Implement a reproducible **DCGAN** baseline on the **CelebA** dataset  
- Visualize generated faces during training  
- Save and restore model checkpoints for later continuation  
- Later steps: Add FID metric, better architectures, and stability improvements

---

## 🖇️ Status
- ✅ Data pipeline + preprocessing  
- ✅ Generator & Discriminator models  
- ✅ Checkpoints and sample saving  
- 🟨 Documentation and fine-tuning  
- ⏭️ Next: Implement evaluation metrics, add configuration system, and enhance generator quality

---

## 📦 Environment Setup

### Requirements
- Python 3.10+
- TensorFlow 2.12+ (GPU recommended)
- NumPy
- Matplotlib
- Pillow
- ImageIO

### Installation
```bash
# Clone the repository
git clone https://github.com/<your-username>/dcgan-celeba.git
cd dcgan-celeba

# Create a virtual environment
python -m venv .venv
# Activate
# Windows:
.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```


## 🧠 Model Overview

### 🧩 Generator
The generator transforms 100-dimensional random noise vectors into 64×64 RGB images using a series of transposed convolutional layers.

**Architecture Summary**
| Layer | Output Shape | Notes |
|-------|---------------|-------|
| Dense | (8×8×256) | Initial projection |
| Reshape | (8, 8, 256) | Start of upsampling |
| Conv2DTranspose (128) | (8, 8, 128) | Upsampling |
| Conv2DTranspose (64) | (16, 16, 64) | Upsampling |
| Conv2DTranspose (32) | (32, 32, 32) | Upsampling |
| Conv2DTranspose (3, tanh) | (64, 64, 3) | Output image |

---

### 🧩 Discriminator
The discriminator distinguishes between **real** and **generated** images using convolutional layers with LeakyReLU activations and dropout for regularization.

**Architecture Summary**
| Layer | Output Shape | Notes |
|-------|---------------|-------|
| Conv2D (64) | (32, 32, 64) | Feature extraction |
| Conv2D (128) | (16, 16, 128) | Deeper feature mapping |
| Conv2D (256) | (8, 8, 256) | Compact representation |
| Flatten + Dense(1) | - | Real/Fake classification output |

---

### ⚙️ Training Configuration
- **Loss Functions:** Binary cross-entropy (from logits)  
- **Optimizers:** Adam (learning rate = 1e-4)  
- **Batch Size:** 128  
- **Epochs:** 50 (default)  
- **Noise Dimension:** 100  
- **Normalization:** Image pixel values scaled to [-1, 1]
## 📸 Results

> Below are sample outputs generated by the DCGAN during training.  
> Images will be updated as training progresses and model quality improves.

| Epoch | Sample Output |
|:-----:|:---------------:|
| 1 | ![epoch1](samples/epoch_0001.png) |
| 10 | ![epoch10](samples/epoch_0010.png) |
| 25 | ![epoch25](samples/epoch_0025.png) |
| 50 | ![epoch50](samples/epoch_0050.png) |

*(Replace the image file names with your actual outputs.  
Each image should be saved automatically in the `samples/` folder during training.)*

---

### 📈 Observations
- As training progresses, generated faces gradually gain sharper and more realistic features.  
- Early epochs typically show blurred or noisy images.  
- Mid to late epochs (around 30–50) begin to capture facial structure, symmetry, and color distribution.  
- Training stability and quality can be improved by adjusting:
  - Learning rates of the generator and discriminator
  - Batch normalization placement
  - Training ratio (e.g., multiple discriminator updates per generator update)

---

### 🧮 Future Improvements
- [ ] Integrate **FID** and **Inception Score** metrics for quantitative evaluation  
- [ ] Add **TensorBoard** visualizations  
- [ ] Try **WGAN-GP** or **Spectral Normalization** for stability  
- [ ] Explore higher-resolution outputs (128×128 or 256×256)  
- [ ] Experiment with **progressive growing GANs**
## 🧪 Roadmap

This section outlines planned improvements and future experiments for the DCGAN project.

### 🎯 Short-Term Goals
- [ ] Save generated image grids after **every epoch** automatically  
- [ ] Add **command-line arguments (CLI)** for dataset path, epochs, and batch size  
- [ ] Integrate **TensorBoard** for live visualization of losses and generated samples  
- [ ] Add **requirements.txt** auto-check for dependencies  
- [ ] Clean up unused imports and paths

### 🚀 Mid-Term Goals
- [ ] Implement **FID (Fréchet Inception Distance)** and **Inception Score** evaluation  
- [ ] Experiment with **different loss functions** (WGAN-GP, LSGAN, etc.)  
- [ ] Add **Spectral Normalization** to the discriminator for training stability  
- [ ] Create a **config file (YAML/JSON)** for training parameters  
- [ ] Add automatic **sample saving** to `/samples/` directory per epoch

### 🧠 Long-Term Goals
- [ ] Implement **Progressive Growing GAN** for higher-resolution face generation  
- [ ] Train and benchmark with **CelebA-HQ** dataset  
- [ ] Experiment with **StyleGAN-like architectures**  
- [ ] Convert the project into a modular **GAN training framework**  
- [ ] Publish trained model weights and interactive notebook demo

---

### 🏁 Milestone Tracking
| Milestone | Status | Description |
|------------|:------:|-------------|
| Baseline DCGAN Training | ✅ | Working implementation on 64×64 CelebA images |
| Checkpointing + Sample Saving | ✅ | Added training checkpoints and grid saving |
| TensorBoard Integration | ⏳ | In progress |
| Evaluation Metrics (FID/IS) | ⏭️ | Planned |
| Advanced Architectures (WGAN-GP/StyleGAN) | 🔜 | Future work |

---

> _“Great models aren’t built overnight — they evolve through experimentation, curiosity, and iteration.”_

## ⚖️ License

This project is open-source under the **MIT License** — see the [`LICENSE`](LICENSE) file for full details.

**Note:**  
The **CelebA dataset** is *not included* and remains under its own license.  
Please follow the [CelebA Terms of Use](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) if you plan to use it.

---

## 👨‍💻 Author

**Mohammad Hemmat**  
🎓 Scholarship Student at **Peter the Great St. Petersburg Polytechnic University, Russia**  
💻 Computer Engineering Student | AI & Robotics Enthusiast | Cybersecurity Explorer  

**Connect with me:**
- [![Telegram](https://img.shields.io/badge/Telegram-Contact-blue?logo=telegram)](https://t.me/Astr0Mh)
- [![Telegram Channel](https://img.shields.io/badge/Telegram-Channel-lightblue?logo=telegram)](https://t.me/TheThoughtsDirectory)
- [![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?logo=linkedin)](https://www.linkedin.com/in/mohammad-hemmat-talab-840412321)

---

## 💬 Acknowledgments

- **CelebA Dataset** – for providing a high-quality dataset for face generation  
- **TensorFlow/Keras Team** – for the excellent deep learning framework  
- **Community contributors** – for open-source GAN implementations that inspired this work  

---

> _“The future belongs to those who build it with code, creativity, and courage.”_  
> — **Mohammad Hemmat**

---

### ⭐ Support

If you find this project useful or interesting, consider giving it a **⭐ star** on GitHub — it helps others find it and supports further development.

